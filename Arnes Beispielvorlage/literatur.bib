@inproceedings{michael_martineau_fast_2007,
	title = {A Fast and Accurate Tensor-based Optical Flow Algorithm Implemented in FPGA},
	isbn = {1550-5790},
	doi = {10.1109/WACV.2007.5},
	abstract = {Many computer vision applications require real-time processing of image data. This requirement is especially critical for autonomous vehicles performing obstacle avoidance, path planning, and target tracking tasks. A quickly calculated and relatively rough motion estimate is more useful for autonomous navigation than a more accurate, but slowly calculated estimate. Recent technology advancements in small unmanned air and ground vehicles make many low-cost surveillance and military applications possible. Most of these applications demand a low power, compact, light weight, and high speed computation platform for processing image data in real time. In most cases, the traditional general purpose processor and sequentially executed software approach does not meet these requirements. In this paper, a tensor-based optical flow algorithm is modified and implemented using field programmable gate array (FPGA) for small unmanned vehicle obstacle avoidance and navigation},
	booktitle = { IEEE Workshop on Applications of Computer Vision, 2007. WACV '07. IEEE Workshop on},
	journal = { IEEE Workshop on Applications of Computer Vision, 2007. WACV '07.},
	author = {Michael Martineau and Zhaoyi Wei and Dah-Jye Lee and M. Martineau},
	year = {2007},
	keywords = {air vehicles,autonomous navigation,autonomous vehicles,collision avoidance,computer vision,field programmable gate array,field programmable gate arrays,FPGA,ground vehicles,image processing,image sequences,low cost surveillance,military applications,motion estimation,obstacle avoidance,path planning,real-time processing,remotely operated vehicles,target tracking,tensor based optical flow algorithm,tensors,video surveillance},
	pages = {18}
},

@inproceedings{valerij_tchernykh_embedded_2006,
	title = {An Embedded Optical Flow Processor for Visual Navigation using Optical Correlator Technology},
	doi = {10.1109/IROS.2006.282620},
	abstract = {The conceptual design of an embedded high performance opto-electronic optical flow processor is presented, which is designed for navigation applications in the field of robotics (ground, aerial, marine) and space (satellites, landing vehicles). It is based on 2D fragment image motion determination by 2D correlation. To meet the real-time performance requirements the principle of joint transform correlation (JTC) and advanced optical correlator technology is used. The paper recalls briefly the underlying principles of optical flow computation and optical correlation, it shows the system layout and the conceptual design for the optical flow processor and it gives preliminary performance results based on a high fidelity simulation of the complete optical processing chain},
	booktitle = {Conference on Intelligent Robots and Systems, 2006 IEEE/RSJ},
	journal = {Conference on Intelligent Robots and Systems, 2006 IEEE/RSJ},
	author = {Valerij Tchernykh and Martin Beck and Klaus Janschek},
	year = {2006},
	keywords = {2D fragment image motion,image motion analysis,integrated optoelectronics,joint transform correlation,optical correlation,optical correlator,optical correlator technology,optical flow,opto-electronic optical flow processor,path planning,robot vision,robotics,visual navigation},
	pages = {67-72}
},

@book{ohm_digitale_1995,
	address = {Berlin},
	title = {Digitale Bildcodierung},
	isbn = {3540585796},
	publisher = {Springer},
	author = {Jens-Rainer Ohm},
	year = {1995}
},

@book{wahl_digitale_1989,
	address = {Berlin},
	edition = {Ber. Nachdruck},
	title = {Digitale Bildsignalverarbeitung. Grundlagen, Verfahren, Beispiele},
	isbn = {3540135863},
	publisher = {Springer},
	author = {Friedrich M. Wahl and Hans Marko},
	year = {1989},
	pages = {191}
},

@book{jaehne_digitale_2005,
	address = {Berlin},
	edition = {6., \~{u}berarb. u. erw. Aufl.},
	title = {Digitale Bildverarbeitung.},
	isbn = {3540249990},
	publisher = {Springer},
	author = {Bernd Jaehne},
	month = may,
	year = {2005},
	pages = {642}
},

@misc{zaunick_echtzeitgenerierung_2006,
	address = {Dresden},
	type = {Diplomarbeit},
	title = {Echtzeitgenerierung von Messsignalen zur Bewegungssteuerung einer fliegenden Plattform aus Bildern der Navigationskamera durch Verarbeitung des optischen Flusses},
	publisher = {Technische Universit"at Dresden, Fakult"at Elektrotechnik und Informationstechnik, Institut f"ur Automatisierungstechnik},
	author = {Edgar Zaunick},
	month = may,
	year = {2006}
},

@misc{technische_universitat_wien_fortgeschrittene_2007,
	title = {Fortgeschrittene Regelstrategien f\~{u}r Visual Servoing},
	copyright = {TU Wien, Fakult\~{a}t Elektrotechnik und Informationstechnik,},
	url = {http://www.acin.tuwien.ac.at},
	journal = {Fortgeschrittene Regelstrategien f\~{u}r Visual Servoing},
	author = {{Technische Universit"at Wien}},
	month = jul,
	year = {2007}
},

@misc{libusb-win32,
	title = {LibUsb-Win32 Universal-USB-Treiber},
	url = {http://libusb-win32.sourceforge.net}
},

@misc{dyblenko_protokoll,
	title = {Protokoll f\~{u}r den Registerzugriff},
	location = {regctrl.xls},
	publisher = {Technische Universit"at Dresden, Fakult"at Elektrotechnik und Informationstechnik, Institut f"ur Automatisierungstechnik},
	author = {Sergey Dyblenko}
},

@article{diaz_subpixel_2006,
	title = {Subpixel motion computing architecture},
	volume = {153},
	issn = {1350-245X},
	doi = {10.1049/ip-vis:20050207},
	abstract = {A pipelined optical-flow processing system that works as a virtual motion sensor has been described. It is based on a field programmable gate array (FPGA) device enabling the easy change of configuring parameters to adapt the sensor to different speeds, light conditions and other environmental factors. It is referred to as a `virtual sensor' because it consists of a conventional camera as front-end supported by an FPGA processing device, which embeds the frame grabber, optical-flow algorithm implementation, output module and some configuration and storage circuitry. This is the first fully stand-alone working optical-flow processing system to include both accuracy and speed of measurement of the platform performance. The customisability of the system for different hardware resources and platforms has also been discussed, showing the resources and performance for a stand-alone board and a PCI co-processing board},
	journal = {IEE Proceedings - Vision, Image and Signal Processing},
	author = {J. Diaz and E. Ros and S. Mota and F. Pelayo and E.M. Ortigosa},
	year = {2006},
	keywords = {field programmable gate arrays,FPGA processing device,frame grabber,fully stand-alone working optical-flow processing system,image motion analysis,image sensors,image sequences,output module,PCI co-processing board,pipelined optical-flow processing system,storage circuitry,subpixel motion computing architecture,virtual motion sensor},
	pages = {869-880}
},

@book{axelson_usb_2001,
	edition = {2Rev Ed},
	title = {USB Complete: Everything You Need to Develop Custom USB Peripherals},
	isbn = {0965081958},
	publisher = {Lakeview Research, U.S.},
	author = {Jan Axelson},
	month = jul,
	year = {2001},
	pages = {450}
},

@unpublished{beck_verbesserung,
	address = {Technische Universit"at Dresden, Fakult"at Elektrotechnik und Informationstechnik, Institut f"ur Automatisierungstechnik},
	type = {Pers\~{o}nliche Information},
	title = {Verbesserung durch Approximation des Maximum-Peaks},
	author = {Martin Beck}
},

@inproceedings{nguyen_xuan_dao_visual_2005,
	title = {Visual navigation for indoor mobile robots using a single camera},
	doi = {10.1109/IROS.2005.1545494},
	abstract = {In this paper, we present a visual navigation algorithm by combining visual localization with the extraction of valid planar regions from a single camera of an indoor mobile robot. Only two pairs of natural line and point are used for the visual localization to take the advantage of fast detection. To track a given landmark model, Lucas-Kanade optical flow algorithm is applied by using gradient descent. We use the odometer data combined with visual information to determine the height of the landmark features. On-ground image features are used to calculate the homography between two image frames and to detect the planar region for navigation. Experimental results show the robustness of the method with respect to image illumination and noises. The performance in indoor environments shows the feasibility of the proposed visual navigation algorithm in realtime.},
	booktitle = {Conference on Intelligent Robots and Systems, 2005. (IROS 2005). 2005 IEEE/RSJ},
	journal = {Conference on Intelligent Robots and Systems, 2005. (IROS 2005). 2005 IEEE/RSJ},
	author = {Nguyen Xuan Dao and Bum-Jae You and Sang-Rok Oh},
	year = {2005},
	keywords = {cameras,distance measurement,feature extraction,gradient descent,gradient methods,homography,image denoising,image feature,image illumination,image noise,image sequences,indoor mobile robot,landmark model,Lucas-Kanade optical flow,mobile robots,natural landmark,natural line,navigation,robot vision,vision-based navigation,Vision-based navigation,visual localization,visual navigation},
	pages = {1992-1997}
}